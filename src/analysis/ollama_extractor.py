# src/analysis/ollama_extractor.py
from langchain_ollama import OllamaLLM
import json
from pathlib import Path
from typing import Dict
import requests
import subprocess
import time
import tiktoken

class OllamaExtractor:
    def __init__(self, model_name: str = "mistral", logger=None, tokenizer_model: str = "cl100k_base"):
        self.logger = logger
        try:
            self.tokenizer = tiktoken.get_encoding(tokenizer_model)

            # Verificar conexi√≥n con Ollama antes de continuar
            self.logger.info("Verificando conexi√≥n con Ollama...")
            if self._verify_ollama_connection():
                self.logger.info("Conexi√≥n con Ollama establecida correctamente")
                    
            # Verificar que el modelo est√° disponible
            self.logger.info(f"Inicializando modelo {model_name}...")
            self.llm = OllamaLLM(
                model=model_name,
                temperature=0.0,
            )
            self.logger.info("Modelo inicializado correctamente")
            
        except Exception as e:
            self.logger.error(f"Error inicializando Ollama: {str(e)}")
            self.logger.warning(f"No se pudo inicializar tokenizador {tokenizer_model}: {e}")
            self.tokenizer = None
            raise

    def _verify_ollama_connection(self):
        """
        Verifica la conexi√≥n con Ollama y su estado
        Returns: True si la conexi√≥n es exitosa
        Raises: ConnectionError si hay problemas de conexi√≥n
        """
        try:
            # Verificar si el servicio est√° corriendo
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code != 200:
                self.logger.error(f"Ollama respondi√≥ con c√≥digo: {response.status_code}")
                raise ConnectionError(f"Error de conexi√≥n con Ollama: c√≥digo {response.status_code}")

            # Verificar si Ollama est√° instalado usando subprocess
            try:
                result = subprocess.run(['ollama', 'list'], 
                                    capture_output=True, 
                                    text=True,
                                    timeout=5)
                if result.returncode == 0:
                    self.logger.info("Ollama est√° instalado correctamente")
                    self.logger.debug(f"Modelos disponibles:\n{result.stdout}")
                else:
                    raise ConnectionError("Error al listar modelos de Ollama")
                    
            except subprocess.TimeoutExpired:
                raise ConnectionError("Timeout al verificar instalaci√≥n de Ollama")
            except FileNotFoundError:
                raise ConnectionError("Ollama no est√° instalado en el sistema")

            return True

        except requests.exceptions.Timeout:
            self.logger.error("Timeout al conectar con Ollama")
            raise ConnectionError("Timeout al conectar con Ollama")
        except requests.exceptions.ConnectionError as e:
            self.logger.error(f"No se puede conectar con Ollama: {str(e)}")
            raise ConnectionError("No se puede establecer conexi√≥n con Ollama. ¬øEst√° el servicio corriendo?")
        except Exception as e:
            self.logger.error(f"Error inesperado al verificar Ollama: {str(e)}")
            raise

    def _count_tokens(self, text: str) -> int:
        """Estima el n√∫mero de tokens en el texto"""
        # Aproximaci√≥n simple: palabras + puntuaci√≥n
        return len(text.split()) + len([c for c in text if c in '.,!?;:()[]{}""'])

    def _chunk_text(self, text: str, max_tokens: int = 6000, overlap_percentage: float = 0.2) -> list:
        try:
            # Validar tokenizador
            if not self.tokenizer:
                self.logger.error("El tokenizador no se inicializ√≥ correctamente")
                raise Exception("Error al inicializar el tokenizador")

            # Validar texto de entrada
            if not text.strip():
                self.logger.error("El texto proporcionado est√° vac√≠o")
                raise ValueError("Texto vac√≠o proporcionado")

            # Tokenizar y logging
            print('[1] Tokenizando texto...')
            tokens = self.tokenizer.encode(text)
            total_tokens = len(tokens)
            self.logger.info(f"Texto tokenizado: {total_tokens} tokens")

            chunks = []
            start = 0
            overlap_tokens = int(max_tokens * overlap_percentage)
            print(f'[2] Iniciando bucle con overlap_tokens={overlap_tokens}')

            while start < total_tokens:
                print(f'\n[3] --- Nuevo chunk ---')
                print(f'[4] Start={start}, Total_tokens={total_tokens}')
                
                end = min(start + max_tokens, total_tokens)
                print(f'[5] End calculado: {end}')

                if end <= start:
                    print(f'[X] ERROR: end({end}) <= start({start})')
                    self.logger.error(f"Rango inv√°lido: end({end}) <= start({start})")
                    raise ValueError("Error en divisi√≥n de chunks: Rango inv√°lido")

                chunk_tokens = tokens[start:end]
                print(f'[6] Tokens en chunk actual: {len(chunk_tokens)}')

                chunk = self.tokenizer.decode(chunk_tokens)
                print(f'[7] Chunk decodificado: {len(chunk)} caracteres')

                chunks.append(chunk)
                print(f'[8] Chunk #{len(chunks)} a√±adido')

                # Calcular siguiente posici√≥n
                if end == total_tokens:
                    print(f'[9] Llegado al final del texto')
                    break

                start = end - overlap_tokens
                if start <= 0:  # Evitar que start vuelva al principio
                    start = end  # Avanzar al final del chunk actual
                
                print(f'[10] Nuevo start calculado: {start}')

            print(f'\n[11] Divisi√≥n completada. Total chunks: {len(chunks)}')
            return chunks
        except Exception as e:
            print(f'[ERROR] Error en _chunk_text: {str(e)}')
            self.logger.error(f"Error en _chunk_text: {str(e)}")
            raise


    def process_chunks(self, text: str) -> Dict:
        try:
            # Validar texto de entrada
            if not text.strip():
                self.logger.error("El texto proporcionado est√° vac√≠o")
                raise ValueError("Texto vac√≠o proporcionado")

            # Contar tokens de manera m√°s precisa
            total_tokens = len(self.tokenizer.encode(text)) if self.tokenizer else self._count_tokens(text)
            MAX_TOKENS = 6000

            # Logging detallado
            self.logger.info(f"Documento original:")
            self.logger.info(f"- Longitud total: {len(text)} caracteres")
            self.logger.info(f"- Tokens totales: {total_tokens}")

            if total_tokens > MAX_TOKENS:
                print(f"\n‚ö†Ô∏è Contenido demasiado largo. Tokens: {total_tokens}, L√≠mite: {MAX_TOKENS}")
                print("Iniciando divisi√≥n de chunks...")

                chunks = self._chunk_text(text)
                if not chunks:
                    raise ValueError("No se generaron chunks v√°lidos")

                print(f"\n‚ö†Ô∏è Dividiendo en {len(chunks)} chunks")
                
                # Procesar chunks
                results = []
                for i, chunk in enumerate(chunks, 1):
                    print(f"üìÑ Procesando chunk {i}/{len(chunks)}")
                    self.logger.info(f"Procesando chunk {i}/{len(chunks)}")
                    
                    try:
                        result = self.extract_information(chunk)
                        if result:
                            results.append(result)
                        else:
                            self.logger.warning(f"Chunk {i} no produjo resultados")
                    except Exception as e:
                        self.logger.error(f"Error procesando chunk {i}: {str(e)}")
                        print(f"‚ùå Error procesando chunk {i}: {str(e)}")

                if not results:
                    raise Exception("No se pudo extraer informaci√≥n de ning√∫n chunk")
                
                return self._combine_results(results)
            else:
                print("‚úÖ Contenido dentro del l√≠mite. Procesando documento completo")
                return self.extract_information(text)
                
        except Exception as e:
            self.logger.error(f"Error en process_chunks: {str(e)}")
            raise

    def _combine_results(self, results: list) -> Dict:
        """Combina los resultados de m√∫ltiples chunks en un √∫nico JSON"""
        try:
            # Validar que hay resultados para combinar
            if not results:
                raise ValueError("Lista de resultados vac√≠a")
                
            # Validar que todos los resultados son diccionarios v√°lidos
            for i, result in enumerate(results):
                if not isinstance(result, dict):
                    self.logger.error(f"Resultado {i} no es un diccionario: {type(result)}")
                    raise ValueError(f"Resultado {i} inv√°lido")

            # Logging de los resultados a combinar
            self.logger.info(f"Combinando {len(results)} resultados")
            
            prompt = """Analiza los siguientes JSONs extra√≠dos de diferentes partes del mismo documento y comb√≠nalos en un √∫nico JSON que siga EXACTAMENTE esta estructura:

            Estructura de JSON de referencia:
            {{
                "tipo_procedimiento": "string",      # Civil, Penal, etc. Ejemplo: "Civil"
                "expediente": "string",              # Ejemplo: "123/2024"
                "juzgado": "string",                # Ejemplo: "Juzgado de Primera Instancia N¬∫ 1 de Madrid"
                "fecha": "string",                  # Ejemplo: "15 de enero de 2024"
                "demandante_nombre": "string",       # Ejemplo: "Juan P√©rez Garc√≠a"
                "demandante_tipo": "string",        # Ejemplo: "Persona f√≠sica"
                "demandante_letrado": "string",     # Ejemplo: "Mar√≠a L√≥pez S√°nchez"
                "demandado_nombre": "string",       # Ejemplo: "Empresa ABC S.L."
                "demandado_tipo": "string",         # Ejemplo: "Persona jur√≠dica"
                "demandado_letrado": "string",      # Ejemplo: "No especificado"
                "descripcion_breve": "string",      # Ejemplo: "Reclamaci√≥n por incumplimiento contractual"
                "materia": "string",                # Ejemplo: "Contractual"
                "pretension": "string",             # Ejemplo: "Resoluci√≥n de contrato e indemnizaci√≥n"
                "cuantia": "string",                # Ejemplo: "50000 euros"
                "hechos_relevantes": [              # Ejemplo: ["Contrato firmado el 1/1/2024", "Incumplimiento el 15/1/2024"]
                    "string"
                ],
                "fundamentos_derecho": [            # Ejemplo: ["Art√≠culo 1124 del C√≥digo Civil", "Art√≠culo 394 LEC"]
                    "string"
                ],
                "sentido_fallo": "string",          # Ejemplo: "Estimaci√≥n total"
                "decision_detalle": "string",       # Ejemplo: "Se estima la demanda en todos sus t√©rminos"
                "indemnizacion": "string",          # Ejemplo: "50000 euros"
                "costas": "string",                 # Ejemplo: "Impuestas a la parte demandada"
                "recurso_tipo": "string",           # Ejemplo: "Apelaci√≥n"
                "recurso_plazo": "string"           # Ejemplo: "20 d√≠as h√°biles"
            }}

            REGLAS ESTRICTAS:
            1. DEBES usar EXACTAMENTE los nombres de campos mostrados arriba
            2. IGNORA campos que no est√©n en esta estructura
            3. Si hay informaci√≥n contradictoria entre los JSONs, usa la m√°s completa o detallada
            4. TODOS los valores deben ser strings o arrays de strings
            5. Usa "No especificado" para campos sin informaci√≥n
            6. El idioma debe ser ESPA√ëOL
            7. NO agregues campos nuevos
            8. NO modifiques los nombres de los campos
            9. Los valores booleanos deben ser "S√≠" o "No"
            10. Las cantidades deben incluir la unidad (ej: "euros", "d√≠as")

            JSONs a combinar:
            {jsons}

            IMPORTANTE: Devuelve SOLO el JSON combinado, sin texto adicional ni explicaciones.
            """
            
            # Convertir resultados a JSON formateado
            json_str = json.dumps(results, indent=2, ensure_ascii=False)
            self.logger.debug(f"JSONs a combinar:\n{json_str}")
            print('json_strjson_str',json_str)
            # Llamar a Ollama
            combined_json = self.llm.invoke(prompt.format(jsons=json_str))
            self.logger.debug(f"Respuesta de Ollama:\n{combined_json}")

            # Limpiar y validar la respuesta
            cleaned_json = self._clean_json_response(combined_json)
            self.logger.debug(f"JSON limpio:\n{cleaned_json}")

            # Intentar parsear el resultado
            try:
                result = json.loads(cleaned_json)
                self.logger.info("Combinaci√≥n exitosa")
                return result
            except json.JSONDecodeError as e:
                self.logger.error(f"Error parseando JSON combinado: {str(e)}")
                self.logger.error(f"JSON inv√°lido:\n{cleaned_json}")
                raise

        except Exception as e:
            self.logger.error(f"Error en _combine_results: {str(e)}")
            raise
        
    def _check_ollama_status(self):
        """Verifica que Ollama est√° instalado y corriendo"""
        print("\n=== Verificando estado de Ollama ===")
        
        # Verificar si Ollama est√° instalado
        try:
            result = subprocess.run(['ollama', 'list'], 
                                 capture_output=True, 
                                 text=True)
            print("Ollama est√° instalado")
            print(f"Modelos disponibles:\n{result.stdout}")
        except FileNotFoundError:
            print("ERROR: Ollama no est√° instalado")
            raise Exception("Ollama no est√° instalado. Visita https://ollama.ai/ para instalarlo")

        # Verificar si el servicio est√° corriendo
        try:
            response = requests.get("http://localhost:11434/api/tags")
            if response.status_code == 200:
                print("Servicio de Ollama est√° corriendo")
            else:
                raise Exception("Servicio no responde correctamente")
        except requests.exceptions.ConnectionError:
            print("ERROR: El servicio de Ollama no est√° corriendo")
            raise Exception("El servicio de Ollama no est√° corriendo. Ejecuta 'ollama serve' primero")

    def extract_information(self, text: str) -> Dict:
        """Extrae informaci√≥n estructurada usando Ollama"""

        if not self._verify_ollama_connection():
            raise ConnectionError("No hay conexi√≥n con Ollama")

        self.logger.info("Iniciando llamada a Ollama...")
        start_time = time.time()
        
        prompt = """Extrae EXACTAMENTE la informaci√≥n del documento judicial. 

            SIGUE ESTAS REGLAS ESTRICTAMENTE:
            1. Usa SOLO la informaci√≥n del texto proporcionado, no intentes a√±adir informaci√≥n inventada
            2. Si no encuentras un dato, usa "No especificado"
            3. Devuelve SOLO un JSON v√°lido
            4. TODOS los valores deben ser strings o arrays de strings

            Estructura JSON:
            {{
                "tipo_procedimiento": "string",      # Civil, Penal, etc. Ejemplo: "Civil"
                "expediente": "string",              # Ejemplo: "123/2024"
                "juzgado": "string",                # Ejemplo: "Juzgado de Primera Instancia N¬∫ 1 de Madrid"
                "fecha": "string",                  # Ejemplo: "15 de enero de 2024"
                "demandante_nombre": "string",       # Ejemplo: "Juan P√©rez Garc√≠a"
                "demandante_tipo": "string",        # Ejemplo: "Persona f√≠sica"
                "demandante_letrado": "string",     # Ejemplo: "Mar√≠a L√≥pez S√°nchez"
                "demandado_nombre": "string",       # Ejemplo: "Empresa ABC S.L."
                "demandado_tipo": "string",         # Ejemplo: "Persona jur√≠dica"
                "demandado_letrado": "string",      # Ejemplo: "No especificado"
                "descripcion_breve": "string",      # Ejemplo: "Reclamaci√≥n por incumplimiento contractual"
                "materia": "string",                # Ejemplo: "Contractual"
                "pretension": "string",             # Ejemplo: "Resoluci√≥n de contrato e indemnizaci√≥n"
                "cuantia": "string",                # Ejemplo: "50000 euros"
                "hechos_relevantes": [              # Ejemplo: ["Contrato firmado el 1/1/2024", "Incumplimiento el 15/1/2024"]
                    "string"
                ],
                "fundamentos_derecho": [            # Ejemplo: ["Art√≠culo 1124 del C√≥digo Civil", "Art√≠culo 394 LEC"]
                    "string"
                ],
                "sentido_fallo": "string",          # Ejemplo: "Estimaci√≥n total"
                "decision_detalle": "string",       # Ejemplo: "Se estima la demanda en todos sus t√©rminos"
                "indemnizacion": "string",          # Ejemplo: "50000 euros"
                "costas": "string",                 # Ejemplo: "Impuestas a la parte demandada"
                "recurso_tipo": "string",           # Ejemplo: "Apelaci√≥n"
                "recurso_plazo": "string"           # Ejemplo: "20 d√≠as h√°biles"
            }}

            TEXTO:
            {text}

            IMPORTANTE: 
            - Responde SOLO con el JSON, sin texto adicional ni explicaciones
            - TODOS los valores deben ser strings, incluyendo n√∫meros y booleanos
            - Los valores booleanos deben ser "S√≠" o "No"
            - Las cantidades deben incluir la unidad (ej: "euros", "d√≠as")
            - El idioma debe ser ESPA√ëOL
            - Usa "No especificado" cuando no encuentres la informaci√≥n
            - Sigue EXACTAMENTE la estructura proporcionada
            """

        try:
            response = None  # Inicializar response
            # Obtener y limpiar respuesta
            response = self.llm.invoke(prompt.format(text=text))

            elapsed_time = time.time() - start_time
            self.logger.info(f"Llamada a Ollama completada en {elapsed_time:.2f} segundos")

            # Debug logging
            self.logger.debug(f"Respuesta raw de Ollama:\n{response}")
            
            # Limpiar la respuesta
            cleaned_response = self._clean_json_response(response)
            self.logger.debug(f"Respuesta limpiada:\n{cleaned_response}")
            
            return json.loads(cleaned_response)
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            self.logger.error(f"Error en llamada a Ollama despu√©s de {elapsed_time:.2f} segundos: {str(e)}")
        
            error_msg = f"Error en extracci√≥n: {str(e)}"
            if response:  # Solo si response tiene un valor
                error_msg += f"\nRespuesta raw: {response}"
            self.logger.error(error_msg)
            raise

    def _clean_json_response(self, response: str) -> str:
        """Limpia la respuesta para obtener JSON v√°lido"""
        try:
            # Si la respuesta ya es un diccionario, convertirla a JSON
            if isinstance(response, dict):
                return json.dumps(response)
   
            # Eliminar espacios y saltos de l√≠nea al inicio y final
            response = response.strip()
            
            # Intentar parsear directamente
            try:
                # Primero intentar parsear la respuesta directa
                json.loads(response)
                return response
            except json.JSONDecodeError:
                # Usar regex para extraer contenido JSON
                import re
                
                # Buscar la primera ocurrencia de un objeto JSON
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                
                if json_match:
                    try:
                        # Intentar parsear el JSON extra√≠do
                        json_str = json_match.group(0)
                        json.loads(json_str)
                        return json_str
                    except json.JSONDecodeError:
                        # Si a√∫n no se puede parsear, registrar el error
                        self.logger.error(f"No se pudo recuperar JSON v√°lido. Respuesta original: {response}")
                        raise
                
                # Si no se encuentra JSON, lanzar excepci√≥n
                raise ValueError(f"No se pudo extraer JSON v√°lido de la respuesta: {response}")
            
        except Exception as e:
            self.logger.error(f"Error limpiando respuesta: {str(e)}")
            raise

    def process_directory(self, input_dir: Path, output_dir: Path):
        """Procesa todos los documentos procesados y extrae su informaci√≥n"""
        input_dir = Path(input_dir)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        for file_path in input_dir.glob("*_processed.json"):
            self.logger.info(f"\nProcesando archivo: {file_path.name}")
            
            try:
                # Leer documento procesado
                with open(file_path, 'r', encoding='utf-8') as f:
                    doc = json.load(f)
                    text_length = len(doc['text'])
                    self.logger.info(f"Documento cargado: {text_length} caracteres")

                # Procesar texto con sistema de chunks
                extracted_info = self.process_chunks(doc['text'])
                
                if extracted_info:
                    # Guardar informaci√≥n extra√≠da
                    output_path = output_dir / f"{file_path.stem}_analyzed.json"
                    with open(output_path, 'w', encoding='utf-8') as f:
                        json.dump(extracted_info, f, ensure_ascii=False, indent=2)
                    self.logger.info(f"Informaci√≥n guardada en: {output_path}")
                else:
                    self.logger.warning(f"No se pudo extraer informaci√≥n de {file_path.name}")

            except Exception as e:
                self.logger.error(f"Error procesando {file_path}: {str(e)}", exc_info=True)
                continue  # Continuar con el siguiente archivo en caso de error